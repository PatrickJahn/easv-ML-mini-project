{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "MSQRy_bsk5Ke",
        "r02VG0cCJTnW",
        "bft_0LHgJeUX",
        "jnukMbLQROrP",
        "gvDpNWpUCPfl"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PatrickJahn/easv-ML-mini-project/blob/main/ML_Mini_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ML Mini Project\n"
      ],
      "metadata": {
        "id": "cmrjEb7dHiHG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The mini project can be a classification or regression task, and it should\n",
        "include\n",
        "\n",
        "1.   Loading and preparation of data\n",
        "2.   Selection, training and fine-tuning of a model\n",
        "3.   Evaluation of the model\n",
        "\n",
        "You can choose between the following model architectures:\n",
        "\n",
        "1.   Multilayer Perceptron\n",
        "2.   Convolutional Neural Network\n",
        "3.   Random Forest\n",
        "4.   Gradient Boosted Decision Trees (incl. Histogram-Based Gradient Boosting)"
      ],
      "metadata": {
        "id": "S0PZjxqBHwyV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Spam Email Classification - Random Forest"
      ],
      "metadata": {
        "id": "sE5kS1VeQHDy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import"
      ],
      "metadata": {
        "id": "MSQRy_bsk5Ke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ],
      "metadata": {
        "id": "d66TYTHok7UN"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading and preparation of data\n"
      ],
      "metadata": {
        "id": "r02VG0cCJTnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
        "column_names = [f\"feature_{i}\" for i in range(57)] + [\"is_spam\"]\n",
        "data = pd.read_csv(url, names=column_names)\n",
        "\n",
        "# Prepare the data\n",
        "X = data.drop(\"is_spam\", axis=1)\n",
        "y = data[\"is_spam\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "JWJfWE-MHhhU"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and fine-tuning of a model"
      ],
      "metadata": {
        "id": "bft_0LHgJeUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Random Forest model\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions and evaluate the model\n",
        "predictions = rf_classifier.predict(X_test)\n",
        "print(classification_report(y_test, predictions))\n",
        "\n",
        "# Fine-tuning the model using GridSearchCV\n",
        "param_grid = {\n",
        "     'n_estimators': [50, 100, 150],\n",
        "    'max_features': ['sqrt', 'log2'],\n",
        "    'max_depth' : [4,5,6,7,8],\n",
        "    'criterion' :['gini', 'entropy']\n",
        "}\n",
        "\n",
        "CV_rfc = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5)\n",
        "CV_rfc.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "viPcRZWRJw7N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "b9654619-b3e6-4a3c-a919-1df534d1e957"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.96       804\n",
            "           1       0.97      0.93      0.95       577\n",
            "\n",
            "    accuracy                           0.96      1381\n",
            "   macro avg       0.96      0.95      0.96      1381\n",
            "weighted avg       0.96      0.96      0.96      1381\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42),\n",
              "             param_grid={'criterion': ['gini', 'entropy'],\n",
              "                         'max_depth': [4, 5, 6, 7, 8],\n",
              "                         'max_features': ['sqrt', 'log2'],\n",
              "                         'n_estimators': [50, 100, 150]})"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42),\n",
              "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
              "                         &#x27;max_depth&#x27;: [4, 5, 6, 7, 8],\n",
              "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
              "                         &#x27;n_estimators&#x27;: [50, 100, 150]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42),\n",
              "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
              "                         &#x27;max_depth&#x27;: [4, 5, 6, 7, 8],\n",
              "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
              "                         &#x27;n_estimators&#x27;: [50, 100, 150]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation of the model"
      ],
      "metadata": {
        "id": "bLQI5Z1DJ-w7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the best parameters and the best score\n",
        "print(\"Best Parameters:\", CV_rfc.best_params_)\n",
        "print(\"Best Score:\", CV_rfc.best_score_)\n",
        "\n",
        "# Evaluate the best model from grid search\n",
        "best_model = CV_rfc.best_estimator_\n",
        "best_predictions = best_model.predict(X_test)\n",
        "print(classification_report(y_test, best_predictions))"
      ],
      "metadata": {
        "id": "OR-7dJuVKMHS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bb7b845-cb90-4357-c3fe-bf93abf0f113"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'criterion': 'entropy', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 100}\n",
            "Best Score: 0.9385093167701865\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.98      0.95       804\n",
            "           1       0.96      0.89      0.93       577\n",
            "\n",
            "    accuracy                           0.94      1381\n",
            "   macro avg       0.95      0.93      0.94      1381\n",
            "weighted avg       0.94      0.94      0.94      1381\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**bold text**# Income Level Prediction - MLP\n"
      ],
      "metadata": {
        "id": "m75e4qy9Qpre"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import"
      ],
      "metadata": {
        "id": "2OgEbMbXnxRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.impute import SimpleImputer"
      ],
      "metadata": {
        "id": "ohBqKcgPVcIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading and preparation of Data\n",
        "\n",
        "> Indented block\n",
        "\n"
      ],
      "metadata": {
        "id": "C-leOAzNn1j2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
        "column_names = [\n",
        "    'age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status',\n",
        "    'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss',\n",
        "    'hours_per_week', 'native_country', 'income'\n",
        "]\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv(url, names=column_names, na_values=' ?', sep=',\\s', engine='python')\n",
        "\n",
        "# Split the data into features and target label\n",
        "X = data.drop('income', axis=1)\n",
        "y = data['income'].apply(lambda x: 1 if x == '>50K' else 0)  # Convert income to binary\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Define categorical and numerical features for preprocessing\n",
        "categorical_features = ['workclass', 'education', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country']\n",
        "numerical_features = ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week']\n",
        "\n",
        "# Create preprocessors for numerical and categorical features\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Bundle preprocessing for numerical and categorical data\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n"
      ],
      "metadata": {
        "id": "sWFRhkVHn4HW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[link text](https://)## Training and fine-tuning of a model"
      ],
      "metadata": {
        "id": "i9gYzIR4oAa-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an MLP model pipeline\n",
        "mlp_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('mlpclassifier', MLPClassifier(hidden_layer_sizes=(50,), max_iter=500, random_state=42))\n",
        "])\n",
        "\n",
        "X_train_small, _, y_train_small, _ = train_test_split(X_train, y_train, train_size=0.3, random_state=42, stratify=y_train)\n",
        "\n",
        "param_grid = {\n",
        "    'mlpclassifier__hidden_layer_sizes': [(50,), (100,)],\n",
        "    'mlpclassifier__activation': ['relu'],\n",
        "    'mlpclassifier__solver': ['adam'],\n",
        "    'mlpclassifier__alpha': [0.0001, 0.001]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(mlp_pipeline, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "# Fine-tuning the MLP model\n",
        "grid_search.fit(X_train_small, y_train_small)\n",
        "\n",
        "# Print out the best parameters\n",
        "print(\"Best parameters found: \", grid_search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNkDPd-boBT0",
        "outputId": "cb5852cd-8445-4088-9d89-52c97277fd33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters found:  {'mlpclassifier__activation': 'relu', 'mlpclassifier__alpha': 0.0001, 'mlpclassifier__hidden_layer_sizes': (100,), 'mlpclassifier__solver': 'adam'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation of the model"
      ],
      "metadata": {
        "id": "33ONWDlpoM0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWOOJynboPHT",
        "outputId": "524020f1-da4d-4f09-c56a-eb8a1004fbd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8242399426758112\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.89      0.88      7417\n",
            "           1       0.64      0.62      0.63      2352\n",
            "\n",
            "    accuracy                           0.82      9769\n",
            "   macro avg       0.76      0.75      0.76      9769\n",
            "weighted avg       0.82      0.82      0.82      9769\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Age Classification from images - CNN"
      ],
      "metadata": {
        "id": "WUktHS7oQv92"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Loading and preparation of data"
      ],
      "metadata": {
        "id": "jnukMbLQROrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import glob\n",
        "import os\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n"
      ],
      "metadata": {
        "id": "FdX-xU1NRKqn"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the path to the images and the attrbutes\n",
        "PATH_TO_ATTR = '/content/faces_data/train.csv'\n",
        "PATH_TO_IMGS = '/content/faces_data/images'\n",
        "\n",
        "\n",
        "# Then we check if there are the same amount of attributes and images\n",
        "data = pd.read_csv(PATH_TO_ATTR)\n",
        "images = os.listdir(PATH_TO_IMGS)\n",
        "\n",
        "print(data.shape[0])\n",
        "print(len(images))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "5MMJVGBxRgBW",
        "outputId": "4417a73f-b937-4131-b689-f8dde34c73b6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/faces_data/train.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-78f8fbfa3d72>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Then we check if there are the same amount of attributes and images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_TO_ATTR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_TO_IMGS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/faces_data/train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w"
      ],
      "metadata": {
        "id": "MEa6kAkOG8EB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can see that there are more attributes than images so we will remove the attributes we dont need\n",
        "data.sort_values(by=\"ID\")\n",
        "data = data.head(len(images))\n",
        "\n",
        "print(data.shape[0])\n",
        "print(len(images))"
      ],
      "metadata": {
        "id": "D8SpQEbjGiKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we will check how many images with each attriute there is\n",
        "data['Class'].unique()"
      ],
      "metadata": {
        "id": "Ky6_ImtfHt6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We check the different values for the Class\n",
        "print(data['Class'].unique())\n",
        "\n",
        "# Replace the Class values with a number\n",
        "data['Class'].replace(['YOUNG','MIDDLE','OLD'],[0,1,2],inplace=True)\n",
        "data.sample(frac=1);\n",
        "\n",
        "# We wawdnt to make sure that the order of image classes is random\n",
        "data.head()"
      ],
      "metadata": {
        "id": "2ios1caWT6y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = mpimg.imread('/content/faces_data/images/1.jpg')\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gyTG2QhwEPxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to read the image an reformat it so all images are the same size and type\n",
        "def readAndFormatImage(path):\n",
        "      img = tf.io.read_file(path)\n",
        "      img = tf.image.decode_jpeg(img, channels=3)\n",
        "      img = tf.image.convert_image_dtype(img, dtype=tf.float32)\n",
        "      img = tf.image.resize(img, (150, 150))\n",
        "      return img"
      ],
      "metadata": {
        "id": "9E8deMg5XS00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to load the data that includes images and respective labels\n",
        "def load_data(image_path, label):\n",
        "    img = readAndFormatImage(image_path)\n",
        "    return (img, label)"
      ],
      "metadata": {
        "id": "BazdwxQhYq-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# built the list of image paths and list of respective responses of the images\n",
        "PATH = \"/content/faces_data/images\"\n",
        "image_paths = []\n",
        "for path in os.listdir(PATH):\n",
        "    image_paths.append(PATH+\"/\"+path)\n",
        "print(len(image_paths))\n",
        "\n",
        "response_list = []\n",
        "\n",
        "for i in image_paths:\n",
        "    _,tail = os.path.split(i)\n",
        "    data.loc\n",
        "    response = data.loc[data['ID'] == tail]['Class'].values[0]\n",
        "    response_list.append(response)\n",
        "print(len(response_list))"
      ],
      "metadata": {
        "id": "MF4dNDgkaCIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the dataset into train and test dataset\n",
        "train_size = int(0.9*(len(image_paths)))\n",
        "print(train_size)\n",
        "test_size = int(0.1*(len(image_paths)))\n",
        "\n",
        "train_set = tf.data.Dataset.from_tensor_slices((image_paths[:train_size], response_list[:train_size]))\n",
        "test_set = tf.data.Dataset.from_tensor_slices((image_paths[test_size:], response_list[test_size:]))"
      ],
      "metadata": {
        "id": "gHN-RxYoaUZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = (train_set\n",
        "    .map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .batch(64)\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "test_set = (test_set\n",
        "    .map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .batch(64)\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")"
      ],
      "metadata": {
        "id": "0bBv95ywaZM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training and fine-tuning of a model"
      ],
      "metadata": {
        "id": "gvDpNWpUCPfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build the layers of CNN model\n",
        "from tensorflow.keras import layers,models\n",
        "\n",
        "cnn_model = models.Sequential([\n",
        "    layers.Conv2D(filters=64, kernel_size=3, activation='relu', input_shape=(150, 150, 3), padding = 'same'),\n",
        "    layers.MaxPooling2D(pool_size=2),\n",
        "\n",
        "\n",
        "    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding = 'same'),\n",
        "    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding = 'same'),\n",
        "    layers.MaxPooling2D(pool_size=2),\n",
        "\n",
        "    layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding = 'same'),\n",
        "    layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding = 'same'),\n",
        "    layers.MaxPooling2D(pool_size=2),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "in87pkjfaefG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view the summary of the cnn model\n",
        "cnn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PW_b7W7Oagtv",
        "outputId": "d4b24551-e11d-4cc0-d779-8e613a900785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_5 (Conv2D)           (None, 150, 150, 64)      1792      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 75, 75, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 75, 75, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 75, 75, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 37, 37, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 37, 37, 256)       295168    \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 37, 37, 256)       590080    \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 18, 18, 256)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 82944)             0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 128)               10616960  \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11734346 (44.76 MB)\n",
            "Trainable params: 11734346 (44.76 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model\n",
        "cnn_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "QoWVppQNai6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "cnn_model.fit(train_set, epochs=10, validation_data=test_set)"
      ],
      "metadata": {
        "id": "5B0tf-20alXh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a3f839e-8546-4616-bd8e-4b1a4007938f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "5/5 [==============================] - 160s 34s/step - loss: 2.1804 - accuracy: 0.2326 - val_loss: 1.3323 - val_accuracy: 0.5347\n",
            "Epoch 2/10\n",
            "5/5 [==============================] - 141s 30s/step - loss: 1.7760 - accuracy: 0.4097 - val_loss: 1.2459 - val_accuracy: 0.5347\n",
            "Epoch 3/10\n",
            "5/5 [==============================] - 143s 30s/step - loss: 1.6010 - accuracy: 0.4410 - val_loss: 1.2888 - val_accuracy: 0.5347\n",
            "Epoch 4/10\n",
            "5/5 [==============================] - 142s 30s/step - loss: 1.6505 - accuracy: 0.3785 - val_loss: 1.2203 - val_accuracy: 0.5347\n",
            "Epoch 5/10\n",
            "5/5 [==============================] - 139s 30s/step - loss: 1.4498 - accuracy: 0.4479 - val_loss: 1.1309 - val_accuracy: 0.5347\n",
            "Epoch 6/10\n",
            "5/5 [==============================] - 140s 29s/step - loss: 1.4674 - accuracy: 0.4306 - val_loss: 1.1361 - val_accuracy: 0.5347\n",
            "Epoch 7/10\n",
            "5/5 [==============================] - 140s 30s/step - loss: 1.4028 - accuracy: 0.4514 - val_loss: 1.1221 - val_accuracy: 0.5347\n",
            "Epoch 8/10\n",
            "5/5 [==============================] - 138s 29s/step - loss: 1.3149 - accuracy: 0.4861 - val_loss: 1.0528 - val_accuracy: 0.5347\n",
            "Epoch 9/10\n",
            "2/5 [===========>..................] - ETA: 1:05 - loss: 1.3891 - accuracy: 0.4531"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluation of the model"
      ],
      "metadata": {
        "id": "srqWxKtKCbkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.evaluate(train_set)"
      ],
      "metadata": {
        "id": "CwbdzcStaoN0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d7b1afb-de91-46ef-955f-a061385f1788"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 51s 10s/step - loss: 1.0614 - accuracy: 0.5069\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0613808631896973, 0.5069444179534912]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test accuracy\n",
        "cnn_model.evaluate(test_set)"
      ],
      "metadata": {
        "id": "s2LUyPmGarCE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8192273-05c6-4066-8adf-0d1539378048"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 30s 6s/step - loss: 1.0223 - accuracy: 0.5347\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.02229905128479, 0.5347222089767456]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred = cnn_model.predict(test_set)"
      ],
      "metadata": {
        "id": "DPw0ldeKatMH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07a30119-4d88-4d37-b0a1-cb1f657b46af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 29s 6s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_labels = [np.argmax(item) for item in test_pred]\n",
        "print(\"Test Predictions response sample:\",y_labels[:10])\n",
        "\n",
        "test_response = response_list[test_size:]\n",
        "print(\"Test True response sample:\", test_response[:10])"
      ],
      "metadata": {
        "id": "SwMDTUHEaw2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b491dcdf-da04-4cb2-fc1b-a2a920b554c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Predictions response sample: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "Test True response sample: [1, 0, 0, 0, 1, 0, 0, 1, 1, 0]\n"
          ]
        }
      ]
    }
  ]
}