{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PatrickJahn/easv-ML-mini-project/blob/main/ML_Mini_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmrjEb7dHiHG"
      },
      "source": [
        "## ML Mini Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0PZjxqBHwyV"
      },
      "source": [
        "The mini project can be a classification or regression task, and it should\n",
        "include\n",
        "\n",
        "1.   Loading and preparation of data\n",
        "2.   Selection, training and fine-tuning of a model\n",
        "3.   Evaluation of the model\n",
        "\n",
        "You can choose between the following model architectures:\n",
        "\n",
        "1.   Multilayer Perceptron\n",
        "2.   Convolutional Neural Network\n",
        "3.   Random Forest\n",
        "4.   Gradient Boosted Decision Trees (incl. Histogram-Based Gradient Boosting)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sE5kS1VeQHDy"
      },
      "source": [
        "# Spam Email Classification - Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r02VG0cCJTnW"
      },
      "source": [
        "## Loading and preparation of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "JWJfWE-MHhhU"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sklearn'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[58], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Import necessary libraries\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
        "column_names = [f'feature_{i}' for i in range(57)] + ['is_spam']\n",
        "df = pd.read_csv(url, names=column_names)\n",
        "\n",
        "# Preprocess the data\n",
        "# Split the data into features and target\n",
        "X = df.drop('is_spam', axis=1)\n",
        "y = df['is_spam']\n",
        "\n",
        "# Splitting the dataset into the Training set and Test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bft_0LHgJeUX"
      },
      "source": [
        "## Training and fine-tuning of a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "viPcRZWRJw7N",
        "outputId": "cf975c7b-fb82-4c56-de22-3321ae7f90bd"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sklearn'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[59], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Import the Random Forest Model and model selection\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Initialize the Random Forest classifier\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
          ]
        }
      ],
      "source": [
        "# Import the Random Forest Model and model selection\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Initialize the Random Forest classifier\n",
        "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "random_forest.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Define a grid of hyperparameters to test\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
        "    'max_features': ['auto', 'sqrt'],  # Number of features to consider at every split\n",
        "    'max_depth': [10, 20, 30, None],  # Maximum number of levels in tree\n",
        "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split a node\n",
        "    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required at each leaf node\n",
        "    'bootstrap': [True, False]  # Method of selecting samples for training each tree\n",
        "}\n",
        "\n",
        "# Initialize the grid search model\n",
        "grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
        "                           param_grid=param_grid,\n",
        "                           cv=3,\n",
        "                           n_jobs=-1,\n",
        "                           verbose=2)\n",
        "\n",
        "# Fit the grid search model\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "\n",
        "# Use the best model for predictions\n",
        "best_grid = grid_search.best_estimator_\n",
        "predictions = best_grid.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLQI5Z1DJ-w7"
      },
      "source": [
        "## Evaluation of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OR-7dJuVKMHS",
        "outputId": "4510959f-c924-4066-b5c4-3b35a9348ea9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9565532223026793\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.96       804\n",
            "           1       0.97      0.93      0.95       577\n",
            "\n",
            "    accuracy                           0.96      1381\n",
            "   macro avg       0.96      0.95      0.96      1381\n",
            "weighted avg       0.96      0.96      0.96      1381\n",
            "\n",
            "Accuracy after fine-tuning: 0.9565532223026793\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.96       804\n",
            "           1       0.97      0.93      0.95       577\n",
            "\n",
            "    accuracy                           0.96      1381\n",
            "   macro avg       0.96      0.95      0.96      1381\n",
            "weighted avg       0.96      0.96      0.96      1381\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Import necessary modules for evaluation\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Make predictions\n",
        "predictions = random_forest.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
        "print(classification_report(y_test, predictions))\n",
        "\n",
        "# Evaluate the best model with fine tuning\n",
        "print(\"Accuracy after fine-tuning:\", accuracy_score(y_test, predictions))\n",
        "print(classification_report(y_test, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m75e4qy9Qpre"
      },
      "source": [
        "# Income Level Prediction - MLPP\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohBqKcgPVcIY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.impute import SimpleImputer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading and preparation of Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
        "column_names = [\n",
        "    'age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status',\n",
        "    'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss',\n",
        "    'hours_per_week', 'native_country', 'income'\n",
        "]\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv(url, names=column_names, na_values=' ?', sep=',\\s', engine='python')\n",
        "\n",
        "# Split the data into features and target label\n",
        "X = data.drop('income', axis=1)\n",
        "y = data['income'].apply(lambda x: 1 if x == '>50K' else 0)  # Convert income to binary\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Define categorical and numerical features for preprocessing\n",
        "categorical_features = ['workclass', 'education', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country']\n",
        "numerical_features = ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week']\n",
        "\n",
        "# Create preprocessors for numerical and categorical features\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Bundle preprocessing for numerical and categorical data\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training and fine-tuning of a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create an MLP model pipeline\n",
        "mlp_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('mlpclassifier', MLPClassifier(hidden_layer_sizes=(50,), max_iter=500, random_state=42))\n",
        "])\n",
        "\n",
        "X_train_small, _, y_train_small, _ = train_test_split(X_train, y_train, train_size=0.3, random_state=42, stratify=y_train)\n",
        "\n",
        "param_grid = {\n",
        "    'mlpclassifier__hidden_layer_sizes': [(50,), (100,)],\n",
        "    'mlpclassifier__activation': ['relu'],\n",
        "    'mlpclassifier__solver': ['adam'],\n",
        "    'mlpclassifier__alpha': [0.0001, 0.001]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(mlp_pipeline, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "# Fine-tuning the MLP model\n",
        "grid_search.fit(X_train_small, y_train_small)\n",
        "\n",
        "# Print out the best parameters\n",
        "print(\"Best parameters found: \", grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUktHS7oQv92"
      },
      "source": [
        "# Age Classification from images - CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnukMbLQROrP"
      },
      "source": [
        "## Loading and preparation of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19906\n",
            "19906\n"
          ]
        }
      ],
      "source": [
        "# Setup the path to the images and the attributes\n",
        "PATH_TO_ATTR = 'Datasets/other/faces/train.csv'\n",
        "PATH_TO_IMGS = 'Datasets/other/faces/Train'\n",
        "\n",
        "\n",
        "# Then we check if there are the same amount of attributes and images\n",
        "data = pd.read_csv(PATH_TO_ATTR)\n",
        "images = os.listdir(PATH_TO_IMGS)\n",
        "\n",
        "print(data.shape[0])\n",
        "print(len(images))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>377.jpg</td>\n",
              "      <td>MIDDLE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>17814.jpg</td>\n",
              "      <td>YOUNG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21283.jpg</td>\n",
              "      <td>MIDDLE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16496.jpg</td>\n",
              "      <td>YOUNG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4487.jpg</td>\n",
              "      <td>MIDDLE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          ID   Class\n",
              "0    377.jpg  MIDDLE\n",
              "1  17814.jpg   YOUNG\n",
              "2  21283.jpg  MIDDLE\n",
              "3  16496.jpg   YOUNG\n",
              "4   4487.jpg  MIDDLE"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Read the csv file to check out the attributes\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>19906</td>\n",
              "      <td>19906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>19906</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>377.jpg</td>\n",
              "      <td>MIDDLE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>10804</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             ID   Class\n",
              "count     19906   19906\n",
              "unique    19906       3\n",
              "top     377.jpg  MIDDLE\n",
              "freq          1   10804"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Check how many of each attribute class their is \n",
        "groupedvalues = data.groupby('Class').count()\n",
        "g = sns.barplot(x='Class', y='ID', data=groupedvalues)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>377.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>17814.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21283.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16496.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4487.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          ID  Class\n",
              "0    377.jpg      1\n",
              "1  17814.jpg      0\n",
              "2  21283.jpg      1\n",
              "3  16496.jpg      0\n",
              "4   4487.jpg      1"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Replace the 3 Class values with a numeric value \n",
        "data['Class'].replace(['YOUNG','MIDDLE','OLD'],[0,1,2],inplace=True)\n",
        "\n",
        "# We want to make sure that the order of image classes is random\n",
        "data.sample(frac=1)\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to read the image an reformat it so all images are the same size and type\n",
        "def readAndFormatImage(path):\n",
        "      img = tf.io.read_file(path)\n",
        "      img = tf.image.decode_jpeg(img, channels=3)\n",
        "      img = tf.image.convert_image_dtype(img, dtype=tf.float32)\n",
        "      img = tf.image.resize(img, (150, 150))\n",
        "      return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data(image_path, label):\n",
        "    img = readAndFormatImage(image_path)\n",
        "    return (img, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19906\n",
            "19906\n"
          ]
        }
      ],
      "source": [
        "# built the list of image paths and list of respective responses of the images\n",
        "image_paths = []\n",
        "for path in os.listdir(PATH_TO_IMGS):\n",
        "    image_paths.append(PATH_TO_IMGS+\"/\"+path)\n",
        "print(len(image_paths))\n",
        "\n",
        "response_list = []\n",
        "\n",
        "for i in image_paths:\n",
        "    _,tail = os.path.split(i)\n",
        "    data.loc\n",
        "    response = data.loc[data['ID'] == tail]['Class'].values[0]\n",
        "    response_list.append(response)\n",
        "print(len(response_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1990\n"
          ]
        }
      ],
      "source": [
        "# split the dataset into train and test dataset\n",
        "train_size = int(0.1*(len(image_paths)))\n",
        "print(train_size)\n",
        "test_size = int(0.1*(len(image_paths)))\n",
        "\n",
        "train_set = tf.data.Dataset.from_tensor_slices((image_paths[:train_size], response_list[:train_size]))\n",
        "test_set = tf.data.Dataset.from_tensor_slices((image_paths[test_size:], response_list[test_size:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set = (train_set\n",
        "    .map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .batch(64)\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "test_set = (test_set\n",
        "    .map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .batch(64)\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training and fine-tuning of a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [],
      "source": [
        "# build the layers of CNN model\n",
        "from tensorflow.keras import layers,models\n",
        "\n",
        "cnn_model = models.Sequential([\n",
        "    layers.Conv2D(filters=64, kernel_size=3, activation='relu', input_shape=(150, 150, 3), padding = 'same'),\n",
        "    layers.MaxPooling2D(pool_size=2),\n",
        "\n",
        "\n",
        "    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding = 'same'),\n",
        "    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding = 'same'),\n",
        "    layers.MaxPooling2D(pool_size=2),\n",
        "\n",
        "    layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding = 'same'),\n",
        "    layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding = 'same'),\n",
        "    layers.MaxPooling2D(pool_size=2),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82944</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">10,616,960</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_46 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m1,792\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_28 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_47 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_48 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_29 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_49 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_50 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_30 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_8 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82944\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │    \u001b[38;5;34m10,616,960\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,734,346</span> (44.76 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,734,346\u001b[0m (44.76 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,734,346</span> (44.76 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,734,346\u001b[0m (44.76 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "cnn_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [],
      "source": [
        "# compile the model\n",
        "cnn_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[123], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# train the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcnn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_set\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:325\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    324\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 325\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(\n\u001b[1;32m    327\u001b[0m         step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    328\u001b[0m     )\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# train the model\n",
        "cnn_model.fit(train_set, epochs=10, validation_data=test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2LUyPmGarCE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 692ms/step - accuracy: 0.1033 - loss: 1.6485\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.6900498867034912, 0.2222222238779068]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# test accuracy\n",
        "cnn_model.evaluate(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPw0ldeKatMH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 650ms/step\n"
          ]
        }
      ],
      "source": [
        "test_pred = cnn_model.predict(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwMDTUHEaw2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Predictions response sample: [3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
          ]
        }
      ],
      "source": [
        "y_labels = [np.argmax(item) for item in test_pred]\n",
        "print(\"Test Predictions response sample:\",y_labels[:10])\n",
        "\n",
        "test_response = response_list[test_size:]\n",
        "print(\"Test True response sample:\", test_response[:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "m75e4qy9Qpre"
      ],
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
